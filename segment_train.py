#!/usr/bin/env python
# -*- encoding: utf-8 -*-
'''
@File    :   segment_train.py
@Time    :   2025/06/17 15:53:43
@Author  :   angkangyu 
'''

"""
segment_train.py - åˆ†å‰²æ¨¡å‹è®­ç»ƒä¸»è„šæœ¬

åŠŸèƒ½ï¼š
æä¾›åˆ†å‰²æ¨¡å‹çš„è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æµç¨‹
æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒä»¥æé«˜è®­ç»ƒæ•ˆç‡å’ŒèŠ‚çœæ˜¾å­˜
æ”¯æŒåŸºäºVal_IoUçš„æ—©åœæœºåˆ¶é¿å…è¿‡æ‹Ÿåˆ
"""

import os
import time
import datetime
import argparse
import numpy as np
from sympy import false, true
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import CosineAnnealingLR
from torch.cuda.amp import GradScaler, autocast
import matplotlib.pyplot as plt
from tqdm import tqdm
import warnings
import platform
import matplotlib
import pandas as pd
import random
matplotlib.use('Agg')  # è®¾ç½®ä¸ºéäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
from torch.optim.lr_scheduler import ReduceLROnPlateau

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from model.model_interface import MInterface
from data.data_interface import SegmentDataInterface
from utils.metrics_utils import (
    SegmentationMetrics, DiceLoss, CombinedLoss, 
    calculate_model_complexity, visualize_results, 
    visualize_training_history, save_training_history_to_excel,
    save_test_results_to_excel, test_model,
    TverskyLoss, FocalTverskyLoss, EnhancedComboLoss, AdaptiveBalancedLoss,RoadIoULoss,IoUBCELoss,
    AdvancedIoULoss,MultiScaleIoULoss,AdaptiveIoULoss,StructuralIoULoss,HybridIoUBCELoss,UltimateRoadIoULoss
)
from  model.Net_parts.public.lovasz_losses import lovasz_hinge, flatten_binary_scores
warnings.filterwarnings("ignore")

# è®¾ç½®ä¸­æ–‡å­—ä½“
system = platform.system()
if system == "Windows":
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
elif system == "Darwin":  # macOS
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'PingFang SC']
else:  # Linux
    plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'SimHei', 'DejaVu Sans']

plt.rcParams['axes.unicode_minus'] = False



class EarlyStoppingIoU:
    """åŸºäºIoUçš„æ—©åœæœºåˆ¶ç±» - IoUè¶Šé«˜è¶Šå¥½"""
    def __init__(self, patience=10, min_delta=0.001, restore_best_weights=True, verbose=True):
        """
        Args:
            patience (int): è¿ç»­å¤šå°‘ä¸ªepochæ²¡æœ‰æ”¹å–„æ—¶åœæ­¢è®­ç»ƒ
            min_delta (float): æœ€å°æ”¹å–„å¹…åº¦ï¼Œå°äºæ­¤å€¼è®¤ä¸ºæ²¡æœ‰æ”¹å–„
            restore_best_weights (bool): æ˜¯å¦æ¢å¤æœ€ä½³æƒé‡
            verbose (bool): æ˜¯å¦æ‰“å°æ—©åœä¿¡æ¯
        """
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.verbose = verbose
        
        self.best_iou = 0.0  # ğŸ”¥ IoUåˆå§‹åŒ–ä¸º0ï¼Œå› ä¸ºè¶Šé«˜è¶Šå¥½
        self.counter = 0
        self.best_weights = None
        self.early_stop = False
        self.best_epoch = 0
        
    def __call__(self, val_iou, model, epoch):
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦æ—©åœ
        
        Args:
            val_iou (float): å½“å‰éªŒè¯IoU
            model: æ¨¡å‹å¯¹è±¡
            epoch (int): å½“å‰epoch
            
        Returns:
            bool: æ˜¯å¦éœ€è¦æ—©åœ
        """
        # ğŸ”¥ IoUæ”¹å–„åˆ¤æ–­ï¼šå½“å‰IoU > å†å²æœ€ä½³IoU + min_delta
        if val_iou > self.best_iou + self.min_delta:
            # éªŒè¯IoUæœ‰æ”¹å–„
            self.best_iou = val_iou
            self.counter = 0
            self.best_epoch = epoch
            if self.restore_best_weights:
                self.best_weights = model.state_dict().copy()
            if self.verbose:
                print(f"Early stopping: validation IoU improved to {val_iou:.6f}")
        else:
            # éªŒè¯IoUæ²¡æœ‰æ”¹å–„
            self.counter += 1
            if self.verbose:
                print(f"Early stopping: no IoU improvement for {self.counter}/{self.patience} epochs (current: {val_iou:.6f}, best: {self.best_iou:.6f})")
            
            if self.counter >= self.patience:
                self.early_stop = True
                if self.verbose:
                    print(f"Early stopping triggered! No IoU improvement for {self.patience} consecutive epochs.")
                    print(f"Best validation IoU: {self.best_iou:.6f} at epoch {self.best_epoch + 1}")
                
                if self.restore_best_weights and self.best_weights is not None:
                    model.load_state_dict(self.best_weights)
                    if self.verbose:
                        print("Restored best model weights")
        
        return self.early_stop



def set_seed(seed=42):
    """è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å®éªŒå¯é‡å¤æ€§"""
    np.random.seed(seed)
    torch.manual_seed(seed)
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    print(f"[Main process] torch seed: {torch.initial_seed()}, np seed: {seed}, random seed: {seed}")


# è§£æå‘½ä»¤è¡Œå‚æ•°
def parse_args():
    parser = argparse.ArgumentParser(description='Segmentation Model Training Script')
    
    # æ•°æ®ç›¸å…³å‚æ•°
    parser.add_argument('--data_dir', type=str, default="data/Massachusetts/split", 
                        help='Dataset directory')
    parser.add_argument('--batch_size', type=int, default=4, 
                        help='Batch size')
    parser.add_argument('--num_workers', type=int, default=20, 
                        help='Number of data loader workers')
    parser.add_argument('--img_size', type=int, default=512, 
                        help='Image size')
    
    # æ¨¡å‹ç›¸å…³å‚æ•°
    parser.add_argument('--in_channels', type=int, default=3, 
                        help='Input channels')
    parser.add_argument('--num_classes', type=int, default=1, 
                        help='Number of classes')
    parser.add_argument('--model_type', type=str, default="DemoNet", 
                        help='Model type')
    
    # è®­ç»ƒç›¸å…³å‚æ•°
    parser.add_argument('--lr', type=float, default=5e-4,
                        help='Learning rate')
    parser.add_argument('--weight_decay', type=float, default=1e-5, 
                        help='Weight decay')
    parser.add_argument('--epochs', type=int, default=150, 
                        help='Training epochs')
    parser.add_argument('--seed', type=int, default=42, 
                        help='Random seed')
    parser.add_argument('--eta_min', type=float, default=1e-6,
                        help='Minimum learning rate for cosine annealing')
        # æ·»åŠ è°ƒåº¦å™¨é€‰æ‹©å‚æ•°
    parser.add_argument('--scheduler', type=str, default='plateau', 
                        choices=['plateau', 'cosine', 'fixed'],
                        help='Learning rate scheduler type')
    
    # ğŸ”¥ åŸºäºIoUçš„æ—©åœæœºåˆ¶å‚æ•°
    parser.add_argument('--early_stopping', action='store_true', default=true,
                        help='Enable early stopping based on validation IoU')
    parser.add_argument('--patience', type=int, default=30,
                        help='Early stopping patience (epochs)')
    parser.add_argument('--min_delta', type=float, default=0.001,
                        help='Minimum IoU improvement to qualify as an improvement')
    parser.add_argument('--no_early_stopping', action='store_true',
                        help='Disable early stopping')
    
    # æ··åˆç²¾åº¦è®­ç»ƒå‚æ•°
    parser.add_argument('--mixed_precision', action='store_true', default=True,
                        help='Enable mixed precision training')
    parser.add_argument('--no_mixed_precision', action='store_true',
                        help='Disable mixed precision training')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--save_dir', type=str, default=None, 
                        help='Results save directory')
    parser.add_argument('--no_test', action='store_true', 
                        help='Skip testing after training')
    parser.add_argument('--loss_type', type=str, default='combined', 
                        choices=['bce', 'dice', 'combined', 'tversky', 'focal_tversky','lovasz_hinge','AdaptiveBalancedLoss',
                                 'RoadIoULoss','IoUBCELoss','EnhancedComboLoss',
                                 'AdvancedIoULoss','MultiScaleIoULoss','AdaptiveIoULoss','StructuralIoULoss','HybridIoUBCELoss','UltimateRoadIoULoss'],
                        help='Loss function type')

    args = parser.parse_args()
    
    # å¤„ç†æ—©åœæœºåˆ¶å‚æ•°
    if args.no_early_stopping:
        args.early_stopping = False
    
    # å¤„ç†æ··åˆç²¾åº¦è®­ç»ƒå‚æ•°
    if args.no_mixed_precision:
        args.mixed_precision = False
    
    if args.save_dir is None:
        mixed_precision_suffix = "_fp16" if args.mixed_precision else "_fp32"
        early_stop_suffix = "_iou_es" if args.early_stopping else ""
        args.save_dir = f"./runs/segmentation/{args.model_type.lower()}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}{mixed_precision_suffix}{early_stop_suffix}"
    
    return args


# è®­ç»ƒæ—¶é—´è®°å½•ç±»
class TrainingTimer:
    """è®­ç»ƒæ—¶é—´è®°å½•å™¨"""
    def __init__(self):
        self.start_time = None
        self.end_time = None
        self.epoch_times = []
        self.total_time = 0
        
    def start_training(self):
        """å¼€å§‹è®­ç»ƒè®¡æ—¶"""
        self.start_time = time.time()
        print(f"Training started at: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
    def start_epoch(self):
        """å¼€å§‹å•ä¸ªepochè®¡æ—¶"""
        return time.time()
        
    def end_epoch(self, epoch_start_time, epoch_num):
        """ç»“æŸå•ä¸ªepochè®¡æ—¶"""
        epoch_time = time.time() - epoch_start_time
        self.epoch_times.append(epoch_time)
        avg_epoch_time = sum(self.epoch_times) / len(self.epoch_times)
        remaining_epochs = len(self.epoch_times)  # è¿™é‡Œåº”è¯¥æ˜¯æ€»epochæ•°å‡å»å½“å‰epoch
        estimated_remaining = avg_epoch_time * remaining_epochs
        
        print(f"Epoch {epoch_num} time: {epoch_time:.2f}s, Average: {avg_epoch_time:.2f}s/epoch")
        
        return epoch_time, avg_epoch_time
        
    def end_training(self):
        """ç»“æŸè®­ç»ƒè®¡æ—¶"""
        self.end_time = time.time()
        self.total_time = self.end_time - self.start_time
        
        print(f"Training ended at: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"Total training time: {self.total_time:.2f}s ({self.total_time/60:.2f}min, {self.total_time/3600:.2f}h)")
        print(f"Average epoch time: {np.mean(self.epoch_times):.2f}s")
        print(f"Fastest epoch: {np.min(self.epoch_times):.2f}s")
        print(f"Slowest epoch: {np.max(self.epoch_times):.2f}s")
        
        return self.total_time
        
    def get_time_info(self):
        """è·å–æ—¶é—´ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_time_seconds': self.total_time,
            'total_time_minutes': self.total_time / 60,
            'total_time_hours': self.total_time / 3600,
            'average_epoch_time': np.mean(self.epoch_times) if self.epoch_times else 0,
            'min_epoch_time': np.min(self.epoch_times) if self.epoch_times else 0,
            'max_epoch_time': np.max(self.epoch_times) if self.epoch_times else 0,
            'start_time': datetime.datetime.fromtimestamp(self.start_time).strftime('%Y-%m-%d %H:%M:%S') if self.start_time else None,
            'end_time': datetime.datetime.fromtimestamp(self.end_time).strftime('%Y-%m-%d %H:%M:%S') if self.end_time else None
        }


def save_realtime_training_history(history, filepath, epoch, best_epoch_info=None):
    """å®æ—¶ä¿å­˜è®­ç»ƒå†å²åˆ°Excelæ–‡ä»¶ï¼ŒåŒ…å«æœ€ä½³æ¨¡å‹ä¿¡æ¯"""
    try:
        # åˆ›å»ºDataFrame
        df_data = {
            'Epoch': list(range(1, epoch + 2)),  # epochä»0å¼€å§‹ï¼Œæ‰€ä»¥+2
            'Train_Loss': history['train_loss'],
            'Val_Loss': history['val_loss'],
            'Train_Dice': history['train_dice'],
            'Val_Dice': history['val_dice'],
            'Train_IoU': history['train_iou'],
            'Val_IoU': history['val_iou'],
            'Train_mIoU': history['train_miou'],
            'Val_mIoU': history['val_miou'],
            'Train_Accuracy': history['train_accuracy'],
            'Val_Accuracy': history['val_accuracy'],
            'Train_Precision': history['train_precision'],
            'Val_Precision': history['val_precision'],
            'Train_Recall': history['train_recall'],
            'Val_Recall': history['val_recall'],
            'Train_F1': history['train_f1'],
            'Val_F1': history['val_f1'],
            'Train_AUC': history['train_auc'],
            'Val_AUC': history['val_auc'],
            'Learning_Rate': history['learning_rate'],
            'Epoch_Time': history['epoch_times']
        }
        
        df = pd.DataFrame(df_data)
        
        # ä¿å­˜åˆ°Excel
        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Training_History', index=False)
            
            # ğŸ”¥ æ·»åŠ æœ€ä½³æ¨¡å‹ä¿¡æ¯åˆ°æ–°çš„å·¥ä½œè¡¨
            if best_epoch_info:
                best_model_df = pd.DataFrame([best_epoch_info])
                best_model_df.to_excel(writer, sheet_name='Best_Model_Info', index=False)
            
        print(f"Real-time training history saved to: {filepath}")
        
    except Exception as e:
        print(f"Warning: Failed to save real-time training history: {e}")


def print_and_log_best_model_info(best_epoch_info, save_dir):
    """æ‰“å°å¹¶è®°å½•æœ€ä½³æ¨¡å‹ä¿¡æ¯"""
    print("\n" + "="*60)
    print("ğŸ† BEST MODEL INFORMATION")
    print("="*60)
    print(f"ğŸ“ Best Epoch: {best_epoch_info['Best_Epoch']}")
    print(f"ğŸ¯ Best Val IoU: {best_epoch_info['Best_Val_IoU']:.6f}")
    print(f"ğŸ² Best Val Dice: {best_epoch_info['Best_Val_Dice']:.6f}")
    print(f"ğŸ“Š Best Val F1: {best_epoch_info['Best_Val_F1']:.6f}")
    print(f"ğŸ“ˆ Best Val Accuracy: {best_epoch_info['Best_Val_Accuracy']:.6f}")
    print(f"ğŸ” Best Val Precision: {best_epoch_info['Best_Val_Precision']:.6f}")
    print(f"ğŸª Best Val Recall: {best_epoch_info['Best_Val_Recall']:.6f}")
    print(f"ğŸ“‰ Best Val Loss: {best_epoch_info['Best_Val_Loss']:.6f}")
    print(f"â±ï¸ Epoch Time: {best_epoch_info['Epoch_Time']:.2f}s")
    print(f"ğŸ“… Timestamp: {best_epoch_info['Timestamp']}")
    print("="*60)
    
    # ä¿å­˜åˆ°å•ç‹¬çš„æ–‡ä»¶
    best_model_file = os.path.join(save_dir, 'best_model_info.txt')
    with open(best_model_file, 'w') as f:
        f.write("BEST MODEL INFORMATION\n")
        f.write("="*60 + "\n")
        for key, value in best_epoch_info.items():
            f.write(f"{key}: {value}\n")
        f.write("="*60 + "\n")
    
    print(f"ğŸ“„ Best model info saved to: {best_model_file}")


# ä¿®æ”¹è®­ç»ƒå‡½æ•°
def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, 
                num_epochs, device, save_dir, num_classes=1, mixed_precision=True, 
                early_stopping=True, patience=10, min_delta=0.001):
    """Train segmentation model with optional mixed precision and IoU-based early stopping"""
    os.makedirs(save_dir, exist_ok=True)
    
    metrics = SegmentationMetrics(num_classes=num_classes)
    timer = TrainingTimer()  # åˆ›å»ºè®¡æ—¶å™¨
    
    # ğŸ”¥ åˆå§‹åŒ–åŸºäºIoUçš„æ—©åœæœºåˆ¶
    early_stopper = None
    if early_stopping:
        early_stopper = EarlyStoppingIoU(
            patience=patience, 
            min_delta=min_delta, 
            restore_best_weights=True, 
            verbose=True
        )
        print(f"IoU-based early stopping enabled: patience={patience}, min_delta={min_delta}")
    else:
        print("Early stopping disabled")
    
    # åˆå§‹åŒ–æ··åˆç²¾åº¦è®­ç»ƒçš„GradScaler
    scaler = GradScaler() if mixed_precision and device.type == 'cuda' else None
    
    # æ£€æŸ¥æ˜¯å¦çœŸæ­£å¯ç”¨äº†æ··åˆç²¾åº¦
    use_amp = mixed_precision and device.type == 'cuda' and scaler is not None
    
    print(f"Mixed precision training: {'Enabled' if use_amp else 'Disabled'}")
    if use_amp:
        print(f"Using GradScaler for automatic mixed precision")
    
    history = {
        'train_loss': [],
        'val_loss': [],
        'train_dice': [],
        'val_dice': [],
        'train_iou': [],
        'val_iou': [],
        'train_miou': [],
        'val_miou': [],
        'train_accuracy': [],
        'val_accuracy': [],
        'train_precision': [],
        'val_precision': [],
        'train_recall': [],
        'val_recall': [],
        'train_f1': [],
        'val_f1': [],
        'train_auc': [],
        'val_auc': [],
        'learning_rate': [],
        'epoch_times': []
    }
    
    best_val_dice = 0.0
    best_val_f1 = 0.0
    best_val_iou = 0.0  # ğŸ”¥ æ·»åŠ æœ€ä½³IoUè·Ÿè¸ª
    
    # ğŸ”¥ æ–°å¢ï¼šæœ€ä½³æ¨¡å‹ä¿¡æ¯è·Ÿè¸ª
    best_epoch_info = {
        'Best_Epoch': 0,
        'Best_Val_IoU': 0.0,
        'Best_Val_Dice': 0.0,
        'Best_Val_F1': 0.0,
        'Best_Val_mIoU': 0.0,
        'Best_Val_Accuracy': 0.0,
        'Best_Val_Precision': 0.0,
        'Best_Val_Recall': 0.0,
        'Best_Val_AUC': 0.0,
        'Best_Val_Loss': float('inf'),
        'Best_Train_IoU': 0.0,
        'Best_Train_Dice': 0.0,
        'Best_Train_Loss': 0.0,
        'Learning_Rate': 0.0,
        'Epoch_Time': 0.0,
        'Timestamp': '',
        'Model_Saved_Path': '',
        'Early_Stopping_Counter': 0,
        'Total_Epochs_So_Far': 0
    }
    
    # å®æ—¶è®­ç»ƒå†å²Excelæ–‡ä»¶è·¯å¾„
    realtime_excel_path = os.path.join(save_dir, 'realtime_training_history.xlsx')
    
    timer.start_training()  # å¼€å§‹è®­ç»ƒè®¡æ—¶
    
    # ğŸ”¥ è®­ç»ƒå¾ªç¯ - æ”¯æŒåŸºäºIoUçš„æ—©åœ
    for epoch in range(num_epochs):
        epoch_start_time = timer.start_epoch()  # å¼€å§‹epochè®¡æ—¶
        print(f"Epoch {epoch+1}/{num_epochs}")
        
        # Training phase
        model.train()
        train_loss = 0.0
        train_dice = 0.0
        train_iou = 0.0
        train_miou = 0.0
        train_accuracy = 0.0
        train_precision = 0.0
        train_recall = 0.0
        train_f1 = 0.0
        train_auc = 0.0
        
        train_progress = tqdm(train_loader, desc="Training")
        for batch_idx, batch in enumerate(train_progress):
            images = batch['image'].to(device)
            masks = batch['mask'].to(device)
            
            # Ensure masks are 0-1 float
            masks = masks.float()
            if masks.max() > 1.0:
                masks = masks / 255.0  # Convert 0-255 to 0-1
            
            # Ensure masks have correct shape and data type
            if len(masks.shape) == 3:
                masks = masks.unsqueeze(1)
            
            optimizer.zero_grad()
            
            # æ··åˆç²¾åº¦è®­ç»ƒçš„å‰å‘ä¼ æ’­
            if use_amp:
                with autocast():
                    outputs = model(images)
                    
                    # Handle model output
                    if isinstance(outputs, list):
                        outputs = outputs[0]
                    
                    # Ensure output and target shapes match
                    if outputs.shape != masks.shape:
                        if len(masks.shape) == 3:
                            masks = masks.unsqueeze(1)
                    
                    loss = criterion(outputs, masks)
            else:
                outputs = model(images)
                
                # Handle model output
                if isinstance(outputs, list):
                    outputs = outputs[0]
                
                # Ensure output and target shapes match
                if outputs.shape != masks.shape:
                    if len(masks.shape) == 3:
                        masks = masks.unsqueeze(1)
                
                loss = criterion(outputs, masks)
            
            # æ··åˆç²¾åº¦è®­ç»ƒçš„åå‘ä¼ æ’­
            if use_amp:
                scaler.scale(loss).backward()
                # Gradient clipping with scaler
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                scaler.step(optimizer)
                scaler.update()
            else:
                loss.backward()
                # Gradient clipping
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
            
            train_loss += loss.item()
            
            # Calculate metrics using the new all-in-one method
            with torch.no_grad():
                # ç¡®ä¿åœ¨è®¡ç®—æŒ‡æ ‡æ—¶ä½¿ç”¨float32ä»¥ä¿è¯ç²¾åº¦
                if use_amp:
                    outputs_for_metrics = outputs.float()
                    masks_for_metrics = masks.float()
                else:
                    outputs_for_metrics = outputs
                    masks_for_metrics = masks
                    
                batch_metrics = metrics.calculate_all_metrics(
                    outputs_for_metrics, 
                    masks_for_metrics.squeeze(1) if masks_for_metrics.shape[1] == 1 else masks_for_metrics
                )
                
                train_dice += batch_metrics['dice']
                train_iou += batch_metrics['iou']
                train_miou += batch_metrics['miou']
                train_accuracy += batch_metrics['accuracy']
                train_precision += batch_metrics['precision']
                train_recall += batch_metrics['recall']
                train_f1 += batch_metrics['f1']
                train_auc += batch_metrics['auc']
            
            train_progress.set_postfix({
                'loss': loss.item(),
                'dice': batch_metrics['dice'],
                'iou': batch_metrics['iou'],
                'miou': batch_metrics['miou'],
                'acc': batch_metrics['accuracy'],
                'f1': batch_metrics['f1']
            })
        
        # Calculate average metrics
        train_loss /= len(train_loader)
        train_dice /= len(train_loader)
        train_iou /= len(train_loader)
        train_miou /= len(train_loader)
        train_accuracy /= len(train_loader)
        train_precision /= len(train_loader)
        train_recall /= len(train_loader)
        train_f1 /= len(train_loader)
        train_auc /= len(train_loader)

        # Validation phase
        model.eval()
        val_loss = 0.0
        val_dice = 0.0
        val_iou = 0.0
        val_miou = 0.0
        val_accuracy = 0.0
        val_precision = 0.0
        val_recall = 0.0
        val_f1 = 0.0
        val_auc = 0.0

        val_progress = tqdm(val_loader, desc="Validation")
        with torch.no_grad():
            for batch in val_progress:
                images = batch['image'].to(device)
                masks = batch['mask'].to(device)
                
                # Process masks
                masks = masks.float()
                if masks.max() > 1.0:
                    masks = masks / 255.0
                
                if len(masks.shape) == 3:
                    masks = masks.unsqueeze(1)
                
                # éªŒè¯é˜¶æ®µä¹Ÿä½¿ç”¨æ··åˆç²¾åº¦
                if use_amp:
                    with autocast():
                        outputs = model(images)
                        
                        if isinstance(outputs, list):
                            outputs = outputs[0]
                        
                        loss = criterion(outputs, masks)
                else:
                    outputs = model(images)
                    
                    if isinstance(outputs, list):
                        outputs = outputs[0]
                    
                    loss = criterion(outputs, masks)
                
                val_loss += loss.item()
                
                # Calculate metrics using the new all-in-one method
                # ç¡®ä¿åœ¨è®¡ç®—æŒ‡æ ‡æ—¶ä½¿ç”¨float32ä»¥ä¿è¯ç²¾åº¦
                if use_amp:
                    outputs_for_metrics = outputs.float()
                    masks_for_metrics = masks.float()
                else:
                    outputs_for_metrics = outputs
                    masks_for_metrics = masks
                    
                batch_metrics = metrics.calculate_all_metrics(
                    outputs_for_metrics, 
                    masks_for_metrics.squeeze(1) if masks_for_metrics.shape[1] == 1 else masks_for_metrics
                )
                
                val_dice += batch_metrics['dice']
                val_iou += batch_metrics['iou']
                val_miou += batch_metrics['miou']
                val_accuracy += batch_metrics['accuracy']
                val_precision += batch_metrics['precision']
                val_recall += batch_metrics['recall']
                val_f1 += batch_metrics['f1']
                val_auc += batch_metrics['auc']
                
                val_progress.set_postfix({
                    'loss': loss.item(),
                    'dice': batch_metrics['dice'],
                    'iou': batch_metrics['iou'],
                    'miou': batch_metrics['miou'],
                    'acc': batch_metrics['accuracy'],
                    'f1': batch_metrics['f1']
                })
        
        # Calculate average validation metrics
        val_loss /= len(val_loader)
        val_dice /= len(val_loader)
        val_iou /= len(val_loader)
        val_miou /= len(val_loader)
        val_accuracy /= len(val_loader)
        val_precision /= len(val_loader)
        val_recall /= len(val_loader)
        val_f1 /= len(val_loader)
        val_auc /= len(val_loader)

        current_lr = optimizer.param_groups[0]['lr']
                # ğŸ”¥ ä¿®å¤ï¼šåªæœ‰åœ¨æœ‰è°ƒåº¦å™¨çš„æƒ…å†µä¸‹æ‰æ›´æ–°å­¦ä¹ ç‡
        if scheduler is not None:
            if isinstance(scheduler, ReduceLROnPlateau):
                scheduler.step(val_iou)   # ReduceLROnPlateauéœ€è¦ä¼ å…¥ç›‘æ§çš„æŒ‡æ ‡
            else:
                scheduler.step() 

        # ç»“æŸepochè®¡æ—¶
        epoch_time, avg_epoch_time = timer.end_epoch(epoch_start_time, epoch+1)

        # Record training history
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['train_dice'].append(train_dice)
        history['val_dice'].append(val_dice)
        history['train_iou'].append(train_iou)
        history['val_iou'].append(val_iou)
        history['train_miou'].append(train_miou)
        history['val_miou'].append(val_miou)
        history['train_accuracy'].append(train_accuracy)
        history['val_accuracy'].append(val_accuracy)
        history['train_precision'].append(train_precision)
        history['val_precision'].append(val_precision)
        history['train_recall'].append(train_recall)
        history['val_recall'].append(val_recall)
        history['train_f1'].append(train_f1)
        history['val_f1'].append(val_f1)
        history['train_auc'].append(train_auc)
        history['val_auc'].append(val_auc)
        history['learning_rate'].append(current_lr)
        history['epoch_times'].append(epoch_time)

        print(f"Epoch {epoch+1}/{num_epochs}")
        print(f"  Train - Loss: {train_loss:.4f}, Dice: {train_dice:.4f}, IoU: {train_iou:.4f}, mIoU: {train_miou:.4f}, Acc: {train_accuracy:.4f}, F1: {train_f1:.4f}")
        print(f"  Val   - Loss: {val_loss:.4f}, Dice: {val_dice:.4f}, IoU: {val_iou:.4f}, mIoU: {val_miou:.4f}, Acc: {val_accuracy:.4f}, F1: {val_f1:.4f}")
        print(f"  Learning Rate: {current_lr:.8f}")
        
        # ğŸ”¥ åŸºäºIoUçš„æ—©åœæ£€æŸ¥
        if early_stopping and early_stopper is not None:
            if early_stopper(val_iou, model, epoch):
                print(f"\nğŸ›‘ Early stopping triggered at epoch {epoch+1}")
                print(f"Best model was at epoch {early_stopper.best_epoch + 1} with validation IoU: {early_stopper.best_iou:.6f}")
                
                # ä¿å­˜æ—©åœä¿¡æ¯åˆ°æ–‡ä»¶
                early_stop_info = {
                    'stopped_at_epoch': epoch + 1,
                    'best_epoch': early_stopper.best_epoch + 1,
                    'best_val_iou': early_stopper.best_iou,
                    'patience': patience,
                    'min_delta': min_delta,
                    'total_planned_epochs': num_epochs,
                    'epochs_saved': num_epochs - (epoch + 1),
                    'metric_monitored': 'Validation_IoU'
                }
                
                with open(os.path.join(save_dir, 'early_stopping_info.txt'), 'w') as f:
                    f.write("Early Stopping Information (IoU-based):\n")
                    f.write("=" * 40 + "\n")
                    for key, value in early_stop_info.items():
                        f.write(f"{key}: {value}\n")
                
                break
        
        # ğŸ”¥ æ›´æ–°æœ€ä½³æŒ‡æ ‡è·Ÿè¸ª (ç°åœ¨ä¸»è¦å…³æ³¨IoU)
        if val_iou > best_val_iou:
            best_val_iou = val_iou
            best_val_dice = val_dice
            best_val_f1 = val_f1
            
            # ğŸ”¥ æ›´æ–°æœ€ä½³æ¨¡å‹ä¿¡æ¯
            best_epoch_info.update({
                'Best_Epoch': epoch + 1,
                'Best_Val_IoU': val_iou,
                'Best_Val_Dice': val_dice,
                'Best_Val_F1': val_f1,
                'Best_Val_mIoU': val_miou,
                'Best_Val_Accuracy': val_accuracy,
                'Best_Val_Precision': val_precision,
                'Best_Val_Recall': val_recall,
                'Best_Val_AUC': val_auc,
                'Best_Val_Loss': val_loss,
                'Best_Train_IoU': train_iou,
                'Best_Train_Dice': train_dice,
                'Best_Train_Loss': train_loss,
                'Learning_Rate': current_lr,
                'Epoch_Time': epoch_time,
                'Timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'Model_Saved_Path': os.path.join(save_dir, 'best_model.pth'),
                'Early_Stopping_Counter': early_stopper.counter if early_stopper else 0,
                'Total_Epochs_So_Far': epoch + 1
            })
            
            torch.save(model.state_dict(), os.path.join(save_dir, 'best_model.pth'))
            print(f"ğŸ† Saved NEW BEST model at epoch {epoch+1}!")
            print(f"   ğŸ“ˆ IoU: {best_val_iou:.6f} (â†‘{val_iou - (history['val_iou'][-2] if len(history['val_iou']) > 1 else 0):.6f})")
            print(f"   ğŸ² Dice: {best_val_dice:.6f}")
            print(f"   ğŸ“Š F1: {best_val_f1:.6f}")
            
            # ğŸ”¥ æ‰“å°æœ€ä½³æ¨¡å‹ä¿¡æ¯
            print_and_log_best_model_info(best_epoch_info, save_dir)

        # ğŸ”¥ å®æ—¶ä¿å­˜è®­ç»ƒå†å²åˆ°Excelï¼ˆåŒ…å«æœ€ä½³æ¨¡å‹ä¿¡æ¯ï¼‰
        save_realtime_training_history(history, realtime_excel_path, epoch, best_epoch_info)
        
        # Visualize validation results at epoch end
        if epoch % 30 == 0 or epoch == num_epochs - 1:
            visualize_batch = next(iter(val_loader))
            images = visualize_batch['image'].to(device)
            masks = visualize_batch['mask']
            filenames = visualize_batch['filename']
            
            model.eval()
            with torch.no_grad():
                if use_amp:
                    with autocast():
                        outputs = model(images)
                else:
                    outputs = model(images)
            
            # ç¡®ä¿å¯è§†åŒ–æ—¶ä½¿ç”¨float32
            if use_amp and hasattr(outputs, 'float'):
                outputs = outputs.float()
            
            for i in range(min(3, len(images))):
                visualize_results(
                    images[i], 
                    masks[i], 
                    outputs[i], 
                    f"epoch_{epoch+1}_{filenames[i]}",
                    os.path.join(save_dir, 'visualizations')
                )
    
    total_training_time = timer.end_training()  # ç»“æŸè®­ç»ƒè®¡æ—¶
    
    # ğŸ”¥ è®­ç»ƒç»“æŸåæ‰“å°æœ€ç»ˆçš„æœ€ä½³æ¨¡å‹ä¿¡æ¯
    print("\n" + "ğŸ‰" * 30)
    print("TRAINING COMPLETED!")
    print("ğŸ‰" * 30)
    print_and_log_best_model_info(best_epoch_info, save_dir)
    
    visualize_training_history(history, os.path.join(save_dir, 'training_history.png'))
    
    # ä¿å­˜è®­ç»ƒå†å²åˆ°Excelï¼ˆæœ€ç»ˆç‰ˆæœ¬ï¼‰
    save_training_history_to_excel(history, os.path.join(save_dir, 'training_history.xlsx'))
    
    # ä¿å­˜è®­ç»ƒæ—¶é—´ä¿¡æ¯
    time_info = timer.get_time_info()
    early_stopped = early_stopping and early_stopper is not None and early_stopper.early_stop
    
    with open(os.path.join(save_dir, 'training_time.txt'), 'w') as f:
        f.write("Training Time Information:\n")
        f.write("=" * 40 + "\n")
        f.write(f"Mixed Precision Training: {'Enabled' if use_amp else 'Disabled'}\n")
        f.write(f"Early Stopping: {'Enabled (IoU-based)' if early_stopping else 'Disabled'}\n")
        if early_stopping:
            f.write(f"Early Stopping Patience: {patience}\n")
            f.write(f"Early Stopping Min Delta: {min_delta}\n")
            f.write(f"Early Stopped: {'Yes' if early_stopped else 'No'}\n")
            if early_stopped:
                f.write(f"Best Validation IoU: {early_stopper.best_iou:.6f}\n")
        f.write(f"Start Time: {time_info['start_time']}\n")
        f.write(f"End Time: {time_info['end_time']}\n")
        f.write(f"Total Training Time: {time_info['total_time_seconds']:.2f} seconds\n")
        f.write(f"Total Training Time: {time_info['total_time_minutes']:.2f} minutes\n")
        f.write(f"Total Training Time: {time_info['total_time_hours']:.2f} hours\n")
        f.write(f"Average Epoch Time: {time_info['average_epoch_time']:.2f} seconds\n")
        f.write(f"Fastest Epoch Time: {time_info['min_epoch_time']:.2f} seconds\n")
        f.write(f"Slowest Epoch Time: {time_info['max_epoch_time']:.2f} seconds\n")
        f.write(f"Total Epochs Completed: {len(history['epoch_times'])}\n")
        f.write(f"Planned Epochs: {num_epochs}\n")
        f.write("\n" + "="*40 + "\n")
        f.write("BEST MODEL INFORMATION:\n")
        f.write("="*40 + "\n")
        for key, value in best_epoch_info.items():
            f.write(f"{key}: {value}\n")
    
    model.load_state_dict(torch.load(os.path.join(save_dir, 'best_model.pth')))
    
    return model, history, time_info, use_amp
def get_model_architecture_info(model):
    """è·å–æ¨¡å‹æ¶æ„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç¼–ç å™¨å’Œè§£ç å™¨åç§°"""
    arch_info = {
        'model_class': model.__class__.__name__,
        'encoder_name': 'Unknown',
        'decoder_name': 'Unknown',
        'encoder_class': 'Unknown',
        'decoder_class': 'Unknown',
        'encoder_params': 0,
        'decoder_params': 0
    }
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰encoderå’Œdecoderå±æ€§
    if hasattr(model, 'encoder'):
        arch_info['encoder_name'] = model.encoder.__class__.__name__
        arch_info['encoder_class'] = str(type(model.encoder))
        arch_info['encoder_params'] = sum(p.numel() for p in model.encoder.parameters() if p.requires_grad)
        
    if hasattr(model, 'decoder'):
        arch_info['decoder_name'] = model.decoder.__class__.__name__
        arch_info['decoder_class'] = str(type(model.decoder))
        arch_info['decoder_params'] = sum(p.numel() for p in model.decoder.parameters() if p.requires_grad)
    
    return arch_info


def save_config_info(args, model, model_info, flops_info, save_dir):
    """å¢å¼ºç‰ˆé…ç½®ä¿¡æ¯ä¿å­˜ï¼ŒåŒ…å«ç¼–ç å™¨è§£ç å™¨ä¿¡æ¯"""
    os.makedirs(save_dir, exist_ok=True)
    
    # è·å–æ¨¡å‹æ¶æ„ä¿¡æ¯
    arch_info = get_model_architecture_info(model)
    
    config_file = os.path.join(save_dir, 'config.txt')
    
    with open(config_file, 'w') as f:
        f.write("=" * 60 + "\n")
        f.write("TRAINING CONFIGURATION\n")
        f.write("=" * 60 + "\n")
        f.write(f"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # æ¨¡å‹æ¶æ„ä¿¡æ¯
        f.write("MODEL ARCHITECTURE:\n")
        f.write("-" * 30 + "\n")
        f.write(f"Model Class: {arch_info['model_class']}\n")
        f.write(f"Encoder: {arch_info['encoder_name']}\n")
        f.write(f"Decoder: {arch_info['decoder_name']}\n")
        f.write(f"Encoder Parameters: {arch_info['encoder_params']:,}\n")
        f.write(f"Decoder Parameters: {arch_info['decoder_params']:,}\n")
        f.write(f"Encoder/Decoder Ratio: {arch_info['encoder_params'] / max(arch_info['decoder_params'], 1):.2f}\n")
        
        f.write("\nCOMMAND LINE ARGUMENTS:\n")
        f.write("-" * 30 + "\n")
        for key, value in vars(args).items():
            f.write(f"{key}: {value}\n")
        
        f.write("\nMODEL INFORMATION:\n")
        f.write("-" * 30 + "\n")
        for key, value in model_info.items():
            f.write(f"{key}: {value}\n")
        
        f.write("\nMODEL COMPLEXITY:\n")
        f.write("-" * 30 + "\n")
        for key, value in flops_info.items():
            f.write(f"{key}: {value}\n")
        
        f.write("\n" + "=" * 60 + "\n")

        f.write(f"Random Seed: {args.seed}\n")
        f.write(f"Random Seed (args.seed): {args.seed}\n")
        f.write(f"Main Process torch.initial_seed: {torch.initial_seed()}\n")   
    # æ§åˆ¶å°æ‰“å°
    print(f"Configuration saved to: {config_file}")
    print(f"\nğŸ—ï¸ Model Architecture Information:")
    print(f"   Model: {arch_info['model_class']}")
    print(f"   ğŸ“¥ Encoder: {arch_info['encoder_name']} ({arch_info['encoder_params']:,} params)")
    print(f"   ğŸ“¤ Decoder: {arch_info['decoder_name']} ({arch_info['decoder_params']:,} params)")
    print(f"   ğŸ“Š Encoder/Decoder Ratio: {arch_info['encoder_params'] / max(arch_info['decoder_params'], 1):.2f}")
    
    return arch_info


# ä¸»å‡½æ•°
def main():
    args = parse_args()
    set_seed(args.seed)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    # æ£€æŸ¥æ··åˆç²¾åº¦è®­ç»ƒçš„å¯ç”¨æ€§
    if args.mixed_precision and device.type != 'cuda':
        print("Warning: Mixed precision training is only available on CUDA devices. Disabling mixed precision.")
        args.mixed_precision = False
    
    if args.mixed_precision and device.type == 'cuda':
        # æ£€æŸ¥CUDAç‰ˆæœ¬å’ŒGPUæ˜¯å¦æ”¯æŒæ··åˆç²¾åº¦
        if torch.cuda.get_device_capability(device)[0] < 7:
            print("Warning: Mixed precision training works best on GPUs with compute capability 7.0 or higher.")
            print(f"Current GPU compute capability: {torch.cuda.get_device_capability(device)}")
    
    print(f"Mixed precision training: {'Enabled' if args.mixed_precision else 'Disabled'}")
    print(f"Early stopping: {'Enabled (IoU-based)' if args.early_stopping else 'Disabled'}")
    if args.early_stopping:
        print(f"Early stopping patience: {args.patience} epochs")
        print(f"Early stopping min delta: {args.min_delta} (IoU improvement)")
    
    os.makedirs(args.save_dir, exist_ok=True)
    
    print("Loading dataset...")
    data_interface = SegmentDataInterface(
        data_dir=args.data_dir,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        img_size=args.img_size
    )
    
    train_loader = data_interface.train_dataloader()
    val_loader = data_interface.val_dataloader()
    test_loader = data_interface.test_dataloader()
    
    print(f"Train set size: {len(train_loader.dataset)} samples")
    print(f"Validation set size: {len(val_loader.dataset)} samples")
    print(f"Test set size: {len(test_loader.dataset)} samples")
    
    # Check data
    sample_batch = next(iter(train_loader))
    print(f"Image shape: {sample_batch['image'].shape}")
    print(f"Mask shape: {sample_batch['mask'].shape}")
    print(f"Image range: [{sample_batch['image'].min():.3f}, {sample_batch['image'].max():.3f}]")
    print(f"Mask range: [{sample_batch['mask'].min():.3f}, {sample_batch['mask'].max():.3f}]")
    print(f"Mask unique values: {torch.unique(sample_batch['mask'])}")
    
    print(f"Creating model: {args.model_type}...")
    model_interface = MInterface(
        model_type=args.model_type,
        in_channels=args.in_channels,
        num_classes=args.num_classes,
        device=device,
        # encoder="resnet50",
        # pretrain=True
    )
    
    model = model_interface.model
    print(f"{args.model_type} model created successfully, parameters: {model_interface.param_count:,}")
    
    # Calculate model complexity
    total_params, trainable_params, flops_info = calculate_model_complexity(
        model, 
        input_size=(args.in_channels, args.img_size, args.img_size), 
        device=device
    )
    
    # å‡†å¤‡æ¨¡å‹ä¿¡æ¯ï¼ˆåœ¨è®­ç»ƒå¼€å§‹å‰ï¼‰
    model_info = {
        'model_type': args.model_type,
        'total_params': total_params,
        'trainable_params': trainable_params,
        'model_size_mb': total_params * 4 / 1024 / 1024,
        'input_size': args.img_size,
        'batch_size': args.batch_size,
        'learning_rate': args.lr,
        'epochs': args.epochs,
        'loss_type': args.loss_type,
        'scheduler': 'ReduceLROnPlateau',
        'eta_min': args.eta_min,
        'mixed_precision': args.mixed_precision,
        'early_stopping': args.early_stopping,
        'early_stopping_metric': 'Validation_IoU' if args.early_stopping else None,
        'patience': args.patience if args.early_stopping else None,
        'min_delta': args.min_delta if args.early_stopping else None,
        'device': str(device),
    }
    
    # åœ¨è®­ç»ƒå¼€å§‹å‰ä¿å­˜é…ç½®ä¿¡æ¯
    # ğŸ”¥ ä½¿ç”¨å¢å¼ºç‰ˆé…ç½®ä¿å­˜ï¼ˆåŒ…å«ç¼–ç å™¨è§£ç å™¨ä¿¡æ¯ï¼‰
    save_config_info(args, model, model_info, flops_info, args.save_dir)
    
    # Select loss function
    if args.loss_type == 'bce':
        criterion = nn.BCEWithLogitsLoss()
    elif args.loss_type == 'dice':
        criterion = DiceLoss()
    elif args.loss_type == 'combined':
        # Adjust weights, favor Dice loss
        criterion = CombinedLoss(dice_weight=0.7, bce_weight=0.3)
    elif args.loss_type == "EnhancedComboLoss":
        criterion = EnhancedComboLoss(dice_weight=0.3, focal_weight=0.4, tversky_weight=0.3)
    elif args.loss_type == 'tversky':
        criterion = TverskyLoss(alpha=0.7, beta=0.3)
    elif args.loss_type == 'focal_tversky':
        criterion = FocalTverskyLoss(alpha=0.7, beta=0.3, gamma=0.75)
    elif args.loss_type == 'lovasz':
        criterion = lovasz_hinge()
    elif args.loss_type == 'AdaptiveBalancedLoss':
        criterion = AdaptiveBalancedLoss()
    elif args.loss_type == 'RoadIoULoss':
        criterion = RoadIoULoss()
    elif args.loss_type == 'IoUBCELoss':
        criterion = IoUBCELoss()
    elif args.loss_type == 'AdvancedIoULoss':
        criterion = AdvancedIoULoss()
    elif args.loss_type == 'MultiScaleIoULoss':
        criterion = MultiScaleIoULoss()
    elif args.loss_type == 'AdaptiveIoULoss':
        criterion = AdaptiveIoULoss()
    elif args.loss_type == 'StructuralIoULoss':
        criterion = StructuralIoULoss()
    elif args.loss_type == 'HybridIoUBCELoss':
        criterion = HybridIoUBCELoss()
    elif args.loss_type == 'UltimateRoadIoULoss':
        criterion = UltimateRoadIoULoss()
    print(f"Using loss function: {args.loss_type}")
    

    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    
    # ğŸ”¥ æ ¹æ®å‚æ•°é€‰æ‹©è°ƒåº¦å™¨ç±»å‹
    if args.scheduler == 'plateau':
        scheduler = ReduceLROnPlateau(
            optimizer,
            mode='max',          # ç›‘æ§IoUï¼Œè¶Šå¤§è¶Šå¥½
            factor=0.5,          # å­¦ä¹ ç‡å‡åŠ
            patience=20,         # 20ä¸ªepochæ²¡æ”¹å–„å°±é™lr
            min_lr=args.eta_min,
            threshold=0.002      # ä¸early stoppingä¸€è‡´
        )
        print(f"Using ReduceLROnPlateau scheduler with patience={scheduler.patience}, factor={scheduler.factor}")
        
    elif args.scheduler == 'cosine':
        scheduler = CosineAnnealingLR(
            optimizer, 
            T_max=args.epochs//10,  
            eta_min=args.eta_min
        )
        print(f"Using CosineAnnealingLR scheduler with T_max={args.epochs//10}, eta_min={args.eta_min}")
        
    elif args.scheduler == 'fixed':
        # ğŸ”¥ å›ºå®šå­¦ä¹ ç‡ - ä¸è¿›è¡Œä»»ä½•è°ƒæ•´
        scheduler = None
        print(f"Using fixed learning rate: {args.lr}")
    
    # ğŸ”¥ åˆ é™¤è¿™è¡Œæœ‰é—®é¢˜çš„ä»£ç ï¼Œå› ä¸ºschedulerå¯èƒ½æ˜¯None
    # print(f"Using ReduceLROnPlateau scheduler with patience={scheduler.patience}, factor={scheduler.factor}, min_lr={scheduler.min_lrs}")
    
    print("\nStarting model training...")
    
    # ... åé¢çš„ä»£ç ä¿æŒä¸å˜ ...
    
    print("\nStarting model training...")
    
    # ğŸ”¥ ä¼ é€’åŸºäºIoUçš„æ—©åœå‚æ•°åˆ°è®­ç»ƒå‡½æ•°
    model, history, time_info, use_amp = train_model(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        criterion=criterion,
        optimizer=optimizer,
        scheduler=scheduler,
        num_epochs=args.epochs,
        device=device,
        save_dir=args.save_dir,
        num_classes=args.num_classes,
        mixed_precision=args.mixed_precision,
        early_stopping=args.early_stopping,
        patience=args.patience,
        min_delta=args.min_delta
    )
    
    if not args.no_test:
        print("\nStarting model testing...")
        test_dice, test_iou, test_miou, test_accuracy, test_precision, test_recall, test_f1, test_auc = test_model(
            model=model,
            test_loader=test_loader,
            device=device,
            save_dir=args.save_dir,
            num_classes=args.num_classes
        )
        
        # æ›´æ–°æ¨¡å‹ä¿¡æ¯ï¼ˆæ·»åŠ è®­ç»ƒæ—¶é—´ä¿¡æ¯ï¼‰
        model_info.update(time_info)
        model_info['mixed_precision_actual'] = use_amp  # å®é™…ä½¿ç”¨çš„æ··åˆç²¾åº¦çŠ¶æ€
        model_info['timestamp'] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        model_info['actual_epochs'] = len(history['epoch_times'])  # å®é™…è®­ç»ƒçš„epochæ•°
        
        test_results = {
            'dice': test_dice,
            'iou': test_iou,
            'miou': test_miou,
            'accuracy': test_accuracy,
            'precision': test_precision,
            'recall': test_recall,
            'f1': test_f1,
            'auc': test_auc
        }
        
        # ä¿å­˜æµ‹è¯•ç»“æœåˆ°Excel
        save_test_results_to_excel(
            test_results, 
            model_info, 
            os.path.join(args.save_dir, 'test_results.xlsx')
        )
        
        # æ›´æ–°é…ç½®æ–‡ä»¶ï¼ˆæ·»åŠ æœ€ç»ˆç»“æœï¼‰
        with open(os.path.join(args.save_dir, 'config.txt'), 'a') as f:
            f.write("\nFINAL TEST RESULTS:\n")
            f.write("-" * 30 + "\n")
            for key, value in test_results.items():
                f.write(f"{key}: {value:.4f}\n")
            
            f.write("\nTRAINING TIME INFORMATION:\n")
            f.write("-" * 30 + "\n")
            for key, value in time_info.items():
                f.write(f"{key}: {value}\n")
            
            f.write(f"\nACTUAL EPOCHS COMPLETED: {len(history['epoch_times'])}/{args.epochs}\n")
        
        torch.save(model.state_dict(), os.path.join(args.save_dir, 'final_model.pth'))
        print(f"Model saved to: {args.save_dir}")
        
        print("\nTraining and testing completed!")
        print(f"Final test results:")
        print(f"  Dice Coefficient: {test_dice:.4f}")
        print(f"  IoU Score: {test_iou:.4f}")
        print(f"  mIoU Score: {test_miou:.4f}")
        print(f"  Accuracy: {test_accuracy:.4f}")
        print(f"  Precision: {test_precision:.4f}")
        print(f"  Recall: {test_recall:.4f}")
        print(f"  F1 Score: {test_f1:.4f}")
        print(f"  AUC Score: {test_auc:.4f}")
        print(f"  Mixed Precision: {'Enabled' if use_amp else 'Disabled'}")
        print(f"  Epochs Completed: {len(history['epoch_times'])}/{args.epochs}")


if __name__ == "__main__":
    main()